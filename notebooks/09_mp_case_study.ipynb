{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = pd.read_csv('../supplemental_data/wikidata_queries/us_members_of_congress.csv')\n",
    "uk = pd.read_csv('../supplemental_data/wikidata_queries/uk_members_of_parliament.csv')\n",
    "jp = pd.read_csv('../supplemental_data/wikidata_queries/jp_members_of_diet.csv')\n",
    "de = pd.read_csv('../supplemental_data/wikidata_queries/de_members_of_bundestag.csv')\n",
    "\n",
    "us['title'] = us['personLabel'].str.replace(' ', '_')\n",
    "uk['title'] = uk['personLabel'].str.replace(' ', '_')\n",
    "jp['title'] = jp['personLabel'].str.replace(' ', '_')\n",
    "de['title'] = de['personLabel'].str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0711618",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_cite_diff = pd.read_csv('../results/reliability_citation_diff.csv')\n",
    "similarity = pd.read_parquet('../results/embeddings_similarities_pairwise_top1_alignments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = pd.merge(us, reliability_cite_diff, on=\"title\", how=\"left\").dropna()\n",
    "uk = pd.merge(uk, reliability_cite_diff, on=\"title\", how=\"left\").dropna()\n",
    "jp = pd.merge(jp, reliability_cite_diff, on=\"title\", how=\"left\").dropna()\n",
    "de = pd.merge(de, reliability_cite_diff, on=\"title\", how=\"left\").dropna()\n",
    "\n",
    "us_similarity = pd.merge(us, similarity, on=\"title\", how=\"left\")\n",
    "uk_similarity = pd.merge(uk, similarity, on=\"title\", how=\"left\")\n",
    "jp_similarity = pd.merge(jp, similarity, on=\"title\", how=\"left\")\n",
    "de_similarity = pd.merge(de, similarity, on=\"title\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine US and UK party similarity histograms into one subplot with outlined (not filled) histograms\n",
    "\n",
    "# --- Categorize US parties\n",
    "def party_category(x):\n",
    "    if x == \"Democratic Party\":\n",
    "        return \"Democratic Party\"\n",
    "    elif x == \"Republican Party\":\n",
    "        return \"Republican Party\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "us_similarity['party_category'] = us_similarity['parliamentaryGroupLabel'].apply(party_category)\n",
    "us_dem = us_similarity[us_similarity['party_category'] == 'Democratic Party']['similarity'].dropna()\n",
    "us_rep = us_similarity[us_similarity['party_category'] == 'Republican Party']['similarity'].dropna()\n",
    "us_other = us_similarity[us_similarity['party_category'] == 'Other']['similarity'].dropna()\n",
    "us_hist_data = [us_dem, us_rep, us_other]\n",
    "us_labels = [\"Democratic Party\", \"Republican Party\", \"Other\"]\n",
    "us_colors = [\"tab:blue\", \"tab:red\", \"tab:gray\"]\n",
    "\n",
    "# --- Categorize UK parties\n",
    "def canonical_party(x):\n",
    "    xl = x.lower()\n",
    "    if \"labour\" in xl:\n",
    "        return \"Labour Party\"\n",
    "    if \"conservative\" in xl and \"unionist\" not in xl:\n",
    "        return \"Conservative Party\"\n",
    "    if \"reform uk\" in xl:\n",
    "        return \"Reform UK\"\n",
    "    return \"Other\"\n",
    "\n",
    "party_colors = {\n",
    "    \"Labour Party\": \"tab:red\",\n",
    "    \"Conservative Party\": \"tab:blue\",\n",
    "    \"Reform UK\": \"tab:gray\",\n",
    "    \"Other\": \"tab:green\"\n",
    "}\n",
    "uk_similarity['party_hist_cat'] = uk_similarity['parliamentaryGroupLabel'].map(canonical_party)\n",
    "uk_labour = uk_similarity[uk_similarity['party_hist_cat'] == 'Labour Party']['similarity'].dropna()\n",
    "uk_cons = uk_similarity[uk_similarity['party_hist_cat'] == 'Conservative Party']['similarity'].dropna()\n",
    "uk_reform = uk_similarity[uk_similarity['party_hist_cat'] == 'Reform UK']['similarity'].dropna()\n",
    "uk_other = uk_similarity[uk_similarity['party_hist_cat'] == \"Other\"]['similarity'].dropna()\n",
    "uk_hist_data = [uk_labour, uk_cons, uk_reform, uk_other]\n",
    "uk_labels = [\"Labour Party\", \"Conservative Party\", \"Reform UK\", \"Other\"]\n",
    "uk_colors = [\n",
    "    party_colors[\"Labour Party\"],\n",
    "    party_colors[\"Conservative Party\"],\n",
    "    party_colors[\"Reform UK\"],\n",
    "    party_colors[\"Other\"]\n",
    "]\n",
    "\n",
    "# --- Plot subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# US histogram\n",
    "axes[0].hist(\n",
    "    us_hist_data,\n",
    "    bins=50,\n",
    "    color=us_colors,\n",
    "    label=us_labels,\n",
    "    alpha=1,\n",
    "    histtype=\"step\",  # outlined, not filled\n",
    "    linewidth=1.7,\n",
    ")\n",
    "axes[0].set_xlabel(\"Per Chunk Similarity\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Count\", fontsize=16)\n",
    "axes[0].set_title(\"US Congress: Similarity by Party\", fontsize=18)  # Changed to fontsize=18\n",
    "axes[0].legend(fontsize=16)\n",
    "\n",
    "# Plot average similarities as vertical lines for Democrats and Republicans (not \"Other\")\n",
    "us_party_means = {\n",
    "    \"Democratic Party\": us_dem.mean(),\n",
    "    \"Republican Party\": us_rep.mean()\n",
    "}\n",
    "us_vline_colors = {\"Democratic Party\": \"tab:blue\", \"Republican Party\": \"tab:red\"}\n",
    "for pname, vcolor in us_vline_colors.items():\n",
    "    axes[0].axvline(us_party_means[pname], color=vcolor, linestyle=\"--\", linewidth=2, label=f\"{pname} mean\")\n",
    "# Adjust legend to show only one entry per party\n",
    "handles0, labels0 = axes[0].get_legend_handles_labels()\n",
    "unique0 = dict(zip(labels0, handles0))\n",
    "axes[0].legend(unique0.values(), unique0.keys(), fontsize=16)\n",
    "\n",
    "# UK histogram\n",
    "axes[1].hist(\n",
    "    uk_hist_data,\n",
    "    bins=50,\n",
    "    color=uk_colors,\n",
    "    label=uk_labels,\n",
    "    alpha=1,\n",
    "    histtype=\"step\",  # outlined, not filled\n",
    "    linewidth=1.7,\n",
    ")\n",
    "axes[1].set_xlabel(\"Per Chunk Similarity\", fontsize=16)\n",
    "axes[1].set_title(\"UK Parliament: Similarity by Parliamentary Group\", fontsize=18)  # Changed to fontsize=18\n",
    "axes[1].legend(fontsize=16)\n",
    "\n",
    "# Plot average similarities for Labour, Conservative, Reform (not Other)\n",
    "uk_party_means = {\n",
    "    \"Labour Party\": uk_labour.mean(),\n",
    "    \"Conservative Party\": uk_cons.mean(),\n",
    "    \"Reform UK\": uk_reform.mean()\n",
    "}\n",
    "uk_vline_colors = {\n",
    "    \"Labour Party\": party_colors[\"Labour Party\"],\n",
    "    \"Conservative Party\": party_colors[\"Conservative Party\"],\n",
    "    \"Reform UK\": party_colors[\"Reform UK\"]\n",
    "}\n",
    "for pname, vcolor in uk_vline_colors.items():\n",
    "    axes[1].axvline(uk_party_means[pname], color=vcolor, linestyle=\"--\", linewidth=2, label=f\"{pname} mean\")\n",
    "# Adjust UK legend as well\n",
    "handles1, labels1 = axes[1].get_legend_handles_labels()\n",
    "unique1 = dict(zip(labels1, handles1))\n",
    "axes[1].legend(unique1.values(), unique1.keys(), fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../graphics/mps/us_uk_party_similarity_subplot.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/grok_domains.json') as f:\n",
    "    grok_domains = json.load(f)\n",
    "\n",
    "with open('../results/wp_domains.json') as f:\n",
    "    wp_domains = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mps = set(\n",
    "    us['title'].tolist() +\n",
    "    uk['title'].tolist() +\n",
    "    jp['title'].tolist() +\n",
    "    de['title'].tolist()\n",
    ")\n",
    "\n",
    "grok_domains_mps = []\n",
    "for p in grok_domains:\n",
    "    for mp in p.keys():\n",
    "        if mp in all_mps:\n",
    "            pdict = p[mp]\n",
    "            for domain, count in pdict.items():\n",
    "                grok_domains_mps.append({\n",
    "                    'title': mp,\n",
    "                    'domain': domain,\n",
    "                    'count': count\n",
    "                })\n",
    "\n",
    "grok_domains_mps_df = pd.DataFrame(grok_domains_mps)\n",
    "\n",
    "wp_domains_mps = []\n",
    "for p in wp_domains:\n",
    "    for mp in p.keys():\n",
    "        if mp in all_mps:\n",
    "            pdict = p[mp]\n",
    "            for domain, count in pdict.items():\n",
    "                wp_domains_mps.append({\n",
    "                    'title': mp,\n",
    "                    'domain': domain,\n",
    "                    'count': count\n",
    "                })\n",
    "\n",
    "wp_domains_mps_df = pd.DataFrame(wp_domains_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fef2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_domains_compare_df = pd.merge(grok_domains_mps_df, wp_domains_mps_df, on=['title', 'domain'], suffixes=['_grok', '_wp'], how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66964a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_scores = pd.read_csv('../supplemental_data/news_reliability/LinRating_Join.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all mp data (us, uk, jp, de) into a single DataFrame with convenient source columns\n",
    "\n",
    "# Add a new column for country to each DataFrame before concatenation\n",
    "us_mp = us.copy()\n",
    "us_mp['country'] = 'us'\n",
    "uk_mp = uk.copy()\n",
    "uk_mp['country'] = 'uk'\n",
    "jp_mp = jp.copy()\n",
    "jp_mp['country'] = 'jp'\n",
    "de_mp = de.copy()\n",
    "de_mp['country'] = 'de'\n",
    "\n",
    "# Combine all country MP DataFrames\n",
    "all_mp_df = pd.concat([us_mp, uk_mp, jp_mp, de_mp], ignore_index=True)\n",
    "\n",
    "# Deduplicate if needed\n",
    "all_mp_df = all_mp_df.drop_duplicates(subset=['title', 'country'])\n",
    "\n",
    "# Optionally, if you only want one row per title, you could pivot or groupby, but keeping long form for easy query/filter\n",
    "\n",
    "# Merge the compare_df with the combined all_mp_df\n",
    "mp_domains_compare_df = pd.merge(\n",
    "    mp_domains_compare_df,\n",
    "    all_mp_df,\n",
    "    on='title',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_domains_compare_df = pd.merge(mp_domains_compare_df, reliability_scores, on='domain', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = mp_domains_compare_df.copy()\n",
    "reliability_df = pd.read_csv('../supplemental_data/perennial_sources_enwiki/enwiki_perennial_list.csv')\n",
    "display_df = pd.merge(display_df, reliability_df, left_on='domain', right_on='source', how='left')\n",
    "\n",
    "mask = display_df['parliamentaryGroupLabel'].isna() & display_df['partyLabel'].notna()\n",
    "display_df.loc[mask, 'parliamentaryGroupLabel'] = display_df.loc[mask, 'partyLabel']\n",
    "display_df = display_df[[\n",
    "    'title', 'domain', 'status', 'count_grok', 'count_wp', 'country', 'parliamentaryGroupLabel'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e37158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mp_reliability_by_party(df, party_order=None, title=None, figsize=(14, 8), show=True, savepath=None):\n",
    "    \"\"\"\n",
    "    Plots stacked bar + diagonal comparison charts for MP/politician data grouped by party:\n",
    "    Shows proportion of sources in each reliability category for Wikipedia and Grokipedia,\n",
    "    with diagonal fills illustrating change between parties.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns: 'parliamentaryGroupLabel', 'status', 'count_grok', 'count_wp'\n",
    "        party_order (list): Optional list of party names to display in order. Others will be grouped as \"Other\"\n",
    "        title (str): Optional custom title for the plot. If None, uses default.\n",
    "        figsize (tuple): Figure size (width, height)\n",
    "        show (bool): If True, calls plt.show() at end\n",
    "        savepath (str): Optional path to save the figure\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    # Normalize status names to standard format\n",
    "    status_mapping = {\n",
    "        'Generally reliable': 'reliable',\n",
    "        'Generally unreliable': 'unreliable',\n",
    "        'Blacklisted': 'blacklist',\n",
    "        'No consensus': 'no_consensus',\n",
    "        'Deprecated': 'deprecated',\n",
    "        'other': 'other'\n",
    "    }\n",
    "    \n",
    "    # Prepare dataframe\n",
    "    df_plot = df.copy()\n",
    "    df_plot['status'] = df_plot['status'].fillna('other')\n",
    "    df_plot['status_normalized'] = df_plot['status'].map(status_mapping).fillna(df_plot['status'].str.lower())\n",
    "    \n",
    "    # Aggregate sums of counts by party and reliability status\n",
    "    agg = df_plot.groupby(['parliamentaryGroupLabel', 'status_normalized']).agg({\n",
    "        'count_grok': 'sum', \n",
    "        'count_wp': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Setup categories, labels, colors (matching plot_reliability_charts)\n",
    "    column_order = ['reliable', 'unreliable', 'blacklist', 'no_consensus', 'deprecated', 'other']\n",
    "    display_names = {\n",
    "        'reliable': 'Generally reliable',\n",
    "        'unreliable': 'Generally unreliable',\n",
    "        'blacklist': 'Blacklisted',\n",
    "        'no_consensus': 'No consensus',\n",
    "        'deprecated': 'Deprecated',\n",
    "        'other': 'Other'\n",
    "    }\n",
    "    color_map = {\n",
    "        'reliable': 'green',\n",
    "        'unreliable': 'red',\n",
    "        'blacklist': 'black',\n",
    "        'no_consensus': 'yellow',\n",
    "        'deprecated': 'orange',\n",
    "        'other': 'grey'\n",
    "    }\n",
    "    \n",
    "    # Pivot for 'grok' and 'wp'\n",
    "    pivot_grok = agg.pivot(index='parliamentaryGroupLabel', columns='status_normalized', values='count_grok').fillna(0)\n",
    "    pivot_wp = agg.pivot(index='parliamentaryGroupLabel', columns='status_normalized', values='count_wp').fillna(0)\n",
    "    \n",
    "    # Only keep columns present\n",
    "    columns_to_plot_grok = [col for col in column_order if col in pivot_grok.columns]\n",
    "    columns_to_plot_wp = [col for col in column_order if col in pivot_wp.columns]\n",
    "    columns_to_plot = [col for col in column_order if col in columns_to_plot_grok or col in columns_to_plot_wp]\n",
    "    \n",
    "    pivot_grok = pivot_grok.reindex(columns=columns_to_plot, fill_value=0)\n",
    "    pivot_wp = pivot_wp.reindex(columns=columns_to_plot, fill_value=0)\n",
    "    \n",
    "    # Handle party ordering\n",
    "    if party_order:\n",
    "        party_labels = [lab for lab in party_order if lab in pivot_grok.index]\n",
    "        others = set(pivot_grok.index) - set(party_labels)\n",
    "        if others:\n",
    "            # Sum all others into a new \"Other\" row\n",
    "            pivot_grok_other = pivot_grok.loc[list(others)].sum().to_frame().T\n",
    "            pivot_grok_other.index = ['Other']\n",
    "            pivot_wp_other = pivot_wp.loc[list(others)].sum().to_frame().T\n",
    "            pivot_wp_other.index = ['Other']\n",
    "            # Concatenate with ordered parties\n",
    "            pivot_grok_plot = pd.concat([pivot_grok.loc[party_labels], pivot_grok_other])\n",
    "            pivot_wp_plot = pd.concat([pivot_wp.loc[party_labels], pivot_wp_other])\n",
    "        else:\n",
    "            pivot_grok_plot = pivot_grok.loc[party_labels]\n",
    "            pivot_wp_plot = pivot_wp.loc[party_labels]\n",
    "    else:\n",
    "        pivot_grok_plot = pivot_grok\n",
    "        pivot_wp_plot = pivot_wp\n",
    "    \n",
    "    # Calculate proportions for each parliamentary group for grok and wp\n",
    "    pivot_prop_grok = pivot_grok_plot.div(pivot_grok_plot.sum(axis=1), axis=0).fillna(0)\n",
    "    pivot_prop_wp = pivot_wp_plot.div(pivot_wp_plot.sum(axis=1), axis=0).fillna(0)\n",
    "    \n",
    "    # Order labels and X axis\n",
    "    labels = pivot_prop_grok.index.tolist()\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    bar_sep = 0.25   # separate more for visible diagonal/area\n",
    "    width = 0.28     # a little narrower bars so there's actual spacing\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    for i, party in enumerate(labels):\n",
    "        left = x[i] - width/2 - bar_sep/2\n",
    "        right = x[i] + width/2 + bar_sep/2\n",
    "        \n",
    "        bottom_wp = 0\n",
    "        bottom_grok = 0\n",
    "        \n",
    "        for col in columns_to_plot:\n",
    "            # WP bar (left)\n",
    "            ax.bar(left, pivot_prop_wp.loc[party, col], width=width, bottom=bottom_wp,\n",
    "                    color=color_map.get(col, 'grey'), edgecolor='none', zorder=2, alpha=0.8)\n",
    "            # Grok bar (right)\n",
    "            ax.bar(right, pivot_prop_grok.loc[party, col], width=width, bottom=bottom_grok,\n",
    "                  color=color_map.get(col, 'grey'), edgecolor='none', zorder=2, alpha=0.8)\n",
    "            \n",
    "            # Diagonal change fill\n",
    "            y0 = bottom_wp + pivot_prop_wp.loc[party, col]\n",
    "            y1 = bottom_grok + pivot_prop_grok.loc[party, col]\n",
    "            ax.fill_between([left + width/2, right - width/2],\n",
    "                            [y0, y1], [bottom_wp, bottom_grok],\n",
    "                            color=color_map.get(col, 'grey'), alpha=0.14, zorder=1, linewidth=0)\n",
    "            \n",
    "            # Stack\n",
    "            bottom_wp += pivot_prop_wp.loc[party, col]\n",
    "            bottom_grok += pivot_prop_grok.loc[party, col]\n",
    "    \n",
    "    # Set axis ticks and labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_ylabel(\"Proportion of Citations\")\n",
    "    plot_title = title if title is not None else \"Source Status by Party\"\n",
    "    ax.set_title(plot_title)\n",
    "    \n",
    "    # Make axis tight with bars\n",
    "    ax.set_ylim(bottom=-0.11, top=1.01)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    \n",
    "    # Add explicit \"Wikipedia\" and \"Grokipedia\" labels for each party on the bottom\n",
    "    for i, party in enumerate(labels):\n",
    "        left = x[i] - width/2 - bar_sep/2\n",
    "        right = x[i] + width/2 + bar_sep/2\n",
    "        y_min = 0\n",
    "        ax.text(left, y_min - 0.04, \"WP\", ha='center', va='top', fontsize=10, color='black')\n",
    "        ax.text(right, y_min - 0.04, \"Grok\", ha='center', va='top', fontsize=10, color='black')\n",
    "    \n",
    "    # Custom legend for source status colors only (reversed order like plot_reliability_charts)\n",
    "    legend_elements = [Patch(facecolor=color_map.get(col, 'grey'), label=display_names.get(col, col)) \n",
    "                      for col in reversed(columns_to_plot)]\n",
    "    ax.legend(handles=legend_elements, title='Source Status', bbox_to_anchor=(1, 1), loc='upper left', framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if savepath:\n",
    "        plt.savefig(savepath)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "# Prepare US MP dataframe and plot\n",
    "us_df = display_df[display_df['country'] == 'us'].copy()\n",
    "plot_mp_reliability_by_party(\n",
    "    us_df, \n",
    "    party_order=['Democratic Party', 'Republican Party'],\n",
    "    title=\"US Congress: Source Category Proportions by Party\",\n",
    "    savepath='../graphics/mps/us_party_reliability.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = display_df[display_df['country'] == 'uk'].copy()\n",
    "plot_mp_reliability_by_party(\n",
    "    uk_df,\n",
    "    party_order=['Labour Party', 'Conservative Party', 'Reform UK'],\n",
    "    title=\"UK Parliament: Source Status by Party\",\n",
    "    savepath='../graphics/mps/uk_party_reliability.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71442ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = mp_domains_compare_df.copy()\n",
    "reliability_df = pd.read_csv('../supplemental_data/perennial_sources_enwiki/enwiki_perennial_list.csv')\n",
    "display_df = pd.merge(display_df, reliability_df, left_on='domain', right_on='source', how='left')\n",
    "\n",
    "mask = display_df['parliamentaryGroupLabel'].isna() & display_df['partyLabel'].notna()\n",
    "display_df.loc[mask, 'parliamentaryGroupLabel'] = display_df.loc[mask, 'partyLabel']\n",
    "display_df = display_df[[\n",
    "    'title', 'domain', 'status', 'count_grok', 'count_wp', 'country', 'parliamentaryGroupLabel', 'pc1'\n",
    "]]\n",
    "\n",
    "def pc1_bucket(x):\n",
    "    try:\n",
    "        if x is not None and not (isinstance(x, float) and math.isnan(x)):\n",
    "            return str(round(float(x) * 5) / 5)\n",
    "        else:\n",
    "            return 'No score'\n",
    "    except (ValueError, TypeError):\n",
    "        return 'No score'\n",
    "\n",
    "display_df['pc1_bucket'] = display_df['pc1'].apply(pc1_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4cbd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mp_reliability_buckets_by_party(df, party_order=None, title=None, figsize=(14, 8), show=True, savepath=None):\n",
    "    \"\"\"\n",
    "    Plots stacked bar + diagonal comparison charts for MP/politician data grouped by party using reliability score buckets:\n",
    "    Shows proportion of sources in each reliability bucket for Wikipedia and Grokipedia,\n",
    "    with diagonal fills illustrating change between parties.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns: 'parliamentaryGroupLabel', 'pc1_bucket', 'count_grok', 'count_wp'\n",
    "        party_order (list): Optional list of party names to display in order. Others will be grouped as \"Other\"\n",
    "        title (str): Optional custom title for the plot. If None, uses default.\n",
    "        figsize (tuple): Figure size (width, height)\n",
    "        show (bool): If True, calls plt.show() at end\n",
    "        savepath (str): Optional path to save the figure\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Patch\n",
    "    import math\n",
    "    \n",
    "    # Prepare dataframe - create pc1_bucket if it doesn't exist\n",
    "    df_plot = df.copy()\n",
    "    if 'pc1_bucket' not in df_plot.columns:\n",
    "        if 'pc1' in df_plot.columns:\n",
    "            def pc1_bucket(x):\n",
    "                try:\n",
    "                    if x is not None and not (isinstance(x, float) and math.isnan(x)):\n",
    "                        return str(round(float(x) * 5) / 5)\n",
    "                    else:\n",
    "                        return 'No score'\n",
    "                except (ValueError, TypeError):\n",
    "                    return 'No score'\n",
    "            df_plot['pc1_bucket'] = df_plot['pc1'].apply(pc1_bucket)\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must have either 'pc1_bucket' or 'pc1' column\")\n",
    "    \n",
    "    # Aggregate sums of counts by party and pc1_bucket (reliability score)\n",
    "    agg = df_plot.groupby(['parliamentaryGroupLabel', 'pc1_bucket']).agg({\n",
    "        'count_grok': 'sum', \n",
    "        'count_wp': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get sorted order of buckets for x-axis/legend, keeping 'No score' at the end if present\n",
    "    bucket_vals = [b for b in agg['pc1_bucket'].unique() if b != 'No score']\n",
    "    try:\n",
    "        bucket_vals_sorted = sorted([float(x) for x in bucket_vals])\n",
    "    except Exception:\n",
    "        bucket_vals_sorted = []\n",
    "    columns_to_plot = [str(v) for v in bucket_vals_sorted]\n",
    "    if 'No score' in agg['pc1_bucket'].unique():\n",
    "        columns_to_plot.append('No score')\n",
    "    \n",
    "    # Map bucket values to display names (range format like '0.0-0.2')\n",
    "    legend_map = {\n",
    "        '0.2': '0.0-0.2',\n",
    "        '0.4': '0.2-0.4',\n",
    "        '0.6': '0.4-0.6',\n",
    "        '0.8': '0.6-0.8',\n",
    "        '1.0': '0.8-1.0',\n",
    "        'No score': 'No score'\n",
    "    }\n",
    "    display_names = {str(b): legend_map.get(str(b), str(b)) for b in columns_to_plot}\n",
    "    if 'No score' in columns_to_plot:\n",
    "        display_names['No score'] = 'No score'\n",
    "    \n",
    "    # Create color map: green (for 1.0), yellow (for 0.5), red (for 0.0), gray for 'No score'\n",
    "    import matplotlib\n",
    "    from matplotlib.colors import to_hex, LinearSegmentedColormap\n",
    "    \n",
    "    num_buckets = len([c for c in columns_to_plot if c != 'No score'])\n",
    "    \n",
    "    # Create a green-yellow-red colormap, where 1.0 is green, 0.5 is yellow, 0.0 is red\n",
    "    spect_cmap = LinearSegmentedColormap.from_list(\n",
    "        \"green_yellow_red\", [(0.0, \"#D73027\"), (0.5, \"#FEE08B\"), (1.0, \"#1A9850\")]  # red, yellow, green\n",
    "    )\n",
    "    # Generate colors corresponding to the bucket edges (sorted lowest to highest)\n",
    "    bucket_values = [float(x) for x in columns_to_plot if x != 'No score']\n",
    "    if bucket_values:\n",
    "        # Normalize bucket_values to 0-1 for colormap mapping\n",
    "        min_b, max_b = min(bucket_values), max(bucket_values)\n",
    "        if min_b != max_b:\n",
    "            norm_bucket_values = [(b - min_b) / (max_b - min_b) for b in bucket_values]\n",
    "        else:\n",
    "            # Edge case: all buckets are the same; use mid value\n",
    "            norm_bucket_values = [0.5 for b in bucket_values]\n",
    "        bucket_colors = [to_hex(spect_cmap(v)) for v in norm_bucket_values]\n",
    "    else:\n",
    "        bucket_colors = []\n",
    "    \n",
    "    color_map = {str(v): bucket_colors[i] for i, v in enumerate(bucket_values)}\n",
    "    color_map['No score'] = 'gray'\n",
    "    \n",
    "    # Pivot for 'grok' and 'wp'\n",
    "    pivot_grok = agg.pivot(index='parliamentaryGroupLabel', columns='pc1_bucket', values='count_grok').fillna(0)\n",
    "    pivot_wp = agg.pivot(index='parliamentaryGroupLabel', columns='pc1_bucket', values='count_wp').fillna(0)\n",
    "    \n",
    "    # Ensure all columns to plot are present in pivots (even if zero)\n",
    "    pivot_grok = pivot_grok.reindex(columns=columns_to_plot, fill_value=0)\n",
    "    pivot_wp = pivot_wp.reindex(columns=columns_to_plot, fill_value=0)\n",
    "    \n",
    "    # Handle party ordering\n",
    "    if party_order:\n",
    "        party_labels = [lab for lab in party_order if lab in pivot_grok.index]\n",
    "        others = set(pivot_grok.index) - set(party_labels)\n",
    "        if others:\n",
    "            # Sum all others into a new \"Other\" row\n",
    "            pivot_grok_other = pivot_grok.loc[list(others)].sum().to_frame().T\n",
    "            pivot_grok_other.index = ['Other']\n",
    "            pivot_wp_other = pivot_wp.loc[list(others)].sum().to_frame().T\n",
    "            pivot_wp_other.index = ['Other']\n",
    "            # Concatenate with ordered parties\n",
    "            pivot_grok_plot = pd.concat([pivot_grok.loc[party_labels], pivot_grok_other])\n",
    "            pivot_wp_plot = pd.concat([pivot_wp.loc[party_labels], pivot_wp_other])\n",
    "        else:\n",
    "            pivot_grok_plot = pivot_grok.loc[party_labels]\n",
    "            pivot_wp_plot = pivot_wp.loc[party_labels]\n",
    "    else:\n",
    "        pivot_grok_plot = pivot_grok\n",
    "        pivot_wp_plot = pivot_wp\n",
    "    \n",
    "    # Calculate proportions for each parliamentary group for grok and wp\n",
    "    pivot_prop_grok = pivot_grok_plot.div(pivot_grok_plot.sum(axis=1), axis=0).fillna(0)\n",
    "    pivot_prop_wp = pivot_wp_plot.div(pivot_wp_plot.sum(axis=1), axis=0).fillna(0)\n",
    "    \n",
    "    # Order labels and X axis\n",
    "    labels = pivot_prop_grok.index.tolist()\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    bar_sep = 0.25   # separate more for visible diagonal/area\n",
    "    width = 0.28     # a little narrower bars so there's actual spacing\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    for i, party in enumerate(labels):\n",
    "        left = x[i] - width/2 - bar_sep/2\n",
    "        right = x[i] + width/2 + bar_sep/2\n",
    "        \n",
    "        bottom_wp = 0\n",
    "        bottom_grok = 0\n",
    "        \n",
    "        for col in columns_to_plot:\n",
    "            # WP bar (left)\n",
    "            ax.bar(left, pivot_prop_wp.loc[party, col], width=width, bottom=bottom_wp,\n",
    "                    color=color_map.get(col, 'grey'), edgecolor='none', zorder=2)\n",
    "            # Grok bar (right)\n",
    "            ax.bar(right, pivot_prop_grok.loc[party, col], width=width, bottom=bottom_grok,\n",
    "                  color=color_map.get(col, 'grey'), edgecolor='none', zorder=2)\n",
    "            \n",
    "            # Diagonal change fill\n",
    "            y0 = bottom_wp + pivot_prop_wp.loc[party, col]\n",
    "            y1 = bottom_grok + pivot_prop_grok.loc[party, col]\n",
    "            ax.fill_between([left + width/2, right - width/2],\n",
    "                            [y0, y1], [bottom_wp, bottom_grok],\n",
    "                            color=color_map.get(col, 'grey'), alpha=0.14, zorder=1, linewidth=0)\n",
    "            \n",
    "            # Stack\n",
    "            bottom_wp += pivot_prop_wp.loc[party, col]\n",
    "            bottom_grok += pivot_prop_grok.loc[party, col]\n",
    "    \n",
    "    # Set axis ticks and labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_ylabel(\"Proportion of Citations\")\n",
    "    plot_title = title if title is not None else \"Source Reliability Score by Party\"\n",
    "    ax.set_title(plot_title)\n",
    "    \n",
    "    # Make axis tight with bars\n",
    "    ax.set_ylim(bottom=-0.11, top=1.01)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    \n",
    "    # Add explicit \"Wikipedia\" and \"Grokipedia\" labels for each party on the bottom\n",
    "    for i, party in enumerate(labels):\n",
    "        left = x[i] - width/2 - bar_sep/2\n",
    "        right = x[i] + width/2 + bar_sep/2\n",
    "        y_min = 0\n",
    "        ax.text(left, y_min - 0.04, \"WP\", ha='center', va='top', fontsize=10, color='black')\n",
    "        ax.text(right, y_min - 0.04, \"Grok\", ha='center', va='top', fontsize=10, color='black')\n",
    "    \n",
    "    # Custom legend for reliability buckets (reversed order - highest first)\n",
    "    rev_legend_cols = list(reversed([col for col in columns_to_plot if col != 'No score']))\n",
    "    if 'No score' in columns_to_plot:\n",
    "        rev_legend_cols.insert(0, 'No score')\n",
    "    \n",
    "    legend_elements = [\n",
    "        Patch(\n",
    "            facecolor=color_map.get(col, 'grey'), \n",
    "            label=display_names.get(col, col)\n",
    "        ) \n",
    "        for col in rev_legend_cols\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, title='Reliability Score\\n(Lin et al. 2023)', \n",
    "              bbox_to_anchor=(1, 1), loc='upper left', framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if savepath:\n",
    "        plt.savefig(savepath)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913db17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare US MP dataframe and plot\n",
    "us_df = display_df[display_df['country'] == 'us'].copy()\n",
    "plot_mp_reliability_buckets_by_party(\n",
    "    us_df,\n",
    "    party_order=['Democratic Party', 'Republican Party'],\n",
    "    title=\"US Congress: Source Reliability Score by Party\",\n",
    "    savepath='../graphics/mps/us_party_reliability_buckets.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare US MP dataframe and plot\n",
    "uk_df = display_df[display_df['country'] == 'uk'].copy()\n",
    "plot_mp_reliability_buckets_by_party(\n",
    "    uk_df,\n",
    "    party_order=['Labour Party', 'Conservative Party', 'Reform UK'],\n",
    "    title=\"UK Parliament: Source Reliability Score by Party\",\n",
    "    savepath='../graphics/mps/uk_party_reliability_buckets.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc0684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
