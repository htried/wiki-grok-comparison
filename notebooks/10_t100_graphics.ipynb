{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "import squarify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_wiki = pd.read_csv('../results/t100_wiki.csv')\n",
    "t100_grok = pd.read_csv('../results/t100_grok.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT 1: Treemap/Area Plot by Individual Domain, Grouped by Type (Wiki vs Grok)\n",
    "# ============================================================================\n",
    "\n",
    "# Get unique types and assign consistent colors\n",
    "all_types = sorted(set(t100_wiki['Type'].unique()) | set(t100_grok['Type'].unique()))\n",
    "colors_map = {\n",
    "    'Academic': '#1f77b4',      # blue\n",
    "    'Database': '#ff7f0e',      # orange\n",
    "    'Government': '#2ca02c',    # green\n",
    "    'Industry site': '#d62728', # red\n",
    "    'News': '#9467bd',          # purple\n",
    "    'Niche media': '#8c564b',   # brown\n",
    "    'Other': '#e377c2',         # pink\n",
    "    'Portal': '#7f7f7f',        # gray\n",
    "    'Reference': '#bcbd22',     # yellow-green\n",
    "    'UGC': '#17becf'            # cyan\n",
    "}\n",
    "\n",
    "# For both, sort by Type (alphabetical), then by size descending within each type\n",
    "def group_and_sort_sites(df, share_col, type_order):\n",
    "    df = df.copy()\n",
    "    df['Type'] = pd.Categorical(df['Type'], categories=type_order, ordered=True)\n",
    "    return df.sort_values(['Type', share_col], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "wiki_domains = group_and_sort_sites(\n",
    "    t100_wiki, 'wiki_share', all_types\n",
    ")\n",
    "grok_domains = group_and_sort_sites(\n",
    "    t100_grok, 'grok_share', all_types\n",
    ")\n",
    "\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "def site_treemap_grouped(ax, df, share_col, title, colors_map, label_thresh=0.0025):\n",
    "    types = df['Type']\n",
    "    colors = [colors_map.get(t, '#cccccc') for t in types]\n",
    "    sizes = df[share_col].values\n",
    "    # Show domain name if above a label threshold, else blank (showing INDIVIDUAL SITES for largest treemap cells)\n",
    "    labels = [\n",
    "        d if s >= label_thresh else \"\"\n",
    "        for d, s in zip(df['domain'], sizes)\n",
    "    ]\n",
    "\n",
    "    # Generate rectangles and positions with squarify, not plotting yet\n",
    "    normed_sizes = squarify.normalize_sizes(sizes, 100, 100)\n",
    "    rects = squarify.squarify(normed_sizes, 0, 0, 100, 100)\n",
    "    for r, color, label in zip(rects, colors, labels):\n",
    "        ax.add_patch(\n",
    "            Rectangle(\n",
    "                (r['x'], r['y']),\n",
    "                r['dx'],\n",
    "                r['dy'],\n",
    "                facecolor=color,\n",
    "                alpha=0.8,\n",
    "                edgecolor='black',    # Draw border\n",
    "                linewidth=0.8\n",
    "            )\n",
    "        )\n",
    "        if label:\n",
    "            label = label.replace('.com', '').replace('.co.uk', '').replace('washingtonpost', 'washington\\npost').replace('pro-football-reference', 'pro\\nfootball\\nref').replace('hollywoodreporter', 'hollywood\\nreporter').replace('animenewsnetwork', 'anime\\nnews\\nnetwork').replace('books.google', 'google\\nbooks').replace('news.google', 'google\\nnews').replace('pmc.ncbi.nlm.nih.gov', 'pubmed').replace('rollingstone', 'rolling\\nstone')\n",
    "            ax.text(\n",
    "                r['x'] + r['dx']/2,\n",
    "                r['y'] + r['dy']/2,\n",
    "                label,\n",
    "                fontsize=10,\n",
    "                ha='center',\n",
    "                va='center'\n",
    "            )\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.axis('off')\n",
    "\n",
    "site_treemap_grouped(\n",
    "    ax1, wiki_domains, 'wiki_share',\n",
    "    'Wikipedia Top 100 Individual Sites (Grouped by Type)', colors_map\n",
    ")\n",
    "site_treemap_grouped(\n",
    "    ax2, grok_domains, 'grok_share',\n",
    "    'Grokipedia Top 100 Individual Sites (Grouped by Type)', colors_map\n",
    ")\n",
    "\n",
    "# Add legend (by type)\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor=colors_map.get(t, '#cccccc'), label=t)\n",
    "    for t in all_types\n",
    "    if (t in wiki_domains['Type'].unique()) or (t in grok_domains['Type'].unique())\n",
    "]\n",
    "fig1.legend(handles=legend_elements, loc='center', bbox_to_anchor=(0.5, 0.025), ncol=min(len(legend_elements), 6))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "plt.savefig('../graphics/domain_treemap_individual_comparison_grouped.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc44a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT 2: Side-by-side Top 100 Lists with Position Changes\n",
    "# ============================================================================\n",
    "\n",
    "# Add position rankings (1-100) to both dataframes\n",
    "# Wikipedia: sorted by wiki share descending\n",
    "wiki_ranked = t100_wiki.copy()\n",
    "wiki_ranked = wiki_ranked.sort_values('wiki_share', ascending=False).reset_index(drop=True)\n",
    "wiki_ranked['position'] = wiki_ranked.index + 1\n",
    "wiki_ranked['wiki_position'] = wiki_ranked['position']\n",
    "\n",
    "# Grokipedia: sorted by grok share descending\n",
    "grok_ranked = t100_grok.copy()\n",
    "grok_ranked = grok_ranked.sort_values('grok_share', ascending=False).reset_index(drop=True)\n",
    "grok_ranked['position'] = grok_ranked.index + 1\n",
    "grok_ranked['grok_position'] = grok_ranked['position']\n",
    "\n",
    "# Create mapping for domains in both lists\n",
    "wiki_positions = dict(zip(wiki_ranked['domain'], wiki_ranked['wiki_position']))\n",
    "grok_positions = dict(zip(grok_ranked['domain'], grok_ranked['grok_position']))\n",
    "\n",
    "# Find domains that appear in both lists\n",
    "common_domains = set(wiki_ranked['domain']) & set(grok_ranked['domain'])\n",
    "\n",
    "# Create figure with single axes for full control\n",
    "fig2, ax = plt.subplots(figsize=(16, 20))\n",
    "fig2.suptitle('Top 100 Domain Rankings: Wikipedia vs Grokipedia', fontsize=20, y=0.995)\n",
    "\n",
    "# Set up coordinate system: x from 0 to 1, y with padding at top and bottom\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-3, 103.5)  # Add padding above and below\n",
    "ax.invert_yaxis()  # Top position at top\n",
    "\n",
    "# Left side (Wikipedia) at x=0.15, Right side (Grokipedia) at x=0.85\n",
    "wiki_x = 0.3\n",
    "grok_x = 0.7\n",
    "\n",
    "# Plot Wikipedia list (left)\n",
    "for idx, row in wiki_ranked.iterrows():\n",
    "    pos = row['wiki_position']\n",
    "    domain = row['domain']\n",
    "    domain_type = row['Type']\n",
    "    color = colors_map.get(domain_type, '#cccccc')\n",
    "    \n",
    "    # Draw colored circle/square for each domain\n",
    "    ax.scatter(wiki_x, pos, s=200, c=color, edgecolors='black', linewidths=0.5, \n",
    "               alpha=0.8, zorder=3)\n",
    "    \n",
    "    # Add domain label outside to the left of circle (clean up for readability)\n",
    "    domain_label = domain.replace('.com', '').replace('.co.uk', '').replace('.org', '')\n",
    "    if len(domain_label) > 20:\n",
    "        domain_label = domain_label[:17] + '...'\n",
    "    ax.text(wiki_x - 0.01, pos, domain_label, ha='right', va='center', fontsize=12,\n",
    "            fontweight='bold' if domain in common_domains else 'normal')\n",
    "\n",
    "# Plot Grokipedia list (right)\n",
    "for idx, row in grok_ranked.iterrows():\n",
    "    pos = row['grok_position']\n",
    "    domain = row['domain']\n",
    "    domain_type = row['Type']\n",
    "    color = colors_map.get(domain_type, '#cccccc')\n",
    "    \n",
    "    # Draw colored circle/square for each domain\n",
    "    ax.scatter(grok_x, pos, s=200, c=color, edgecolors='black', linewidths=0.5, \n",
    "               alpha=0.8, zorder=3)\n",
    "    \n",
    "    # Add domain label outside to the right of circle (clean up for readability)\n",
    "    domain_label = domain.replace('.com', '').replace('.co.uk', '').replace('.org', '')\n",
    "    if len(domain_label) > 20:\n",
    "        domain_label = domain_label[:17] + '...'\n",
    "    ax.text(grok_x + 0.01, pos, domain_label, ha='left', va='center', fontsize=12,\n",
    "            fontweight='bold' if domain in common_domains else 'normal')\n",
    "\n",
    "# Draw connecting lines for domains in both lists\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "for domain in common_domains:\n",
    "    wiki_pos = wiki_positions[domain]\n",
    "    grok_pos = grok_positions[domain]\n",
    "    pos_change = grok_pos - wiki_pos\n",
    "    \n",
    "    # Get color from Wikipedia type (or use gray if not found)\n",
    "    wiki_row = wiki_ranked[wiki_ranked['domain'] == domain].iloc[0]\n",
    "    line_color = colors_map.get(wiki_row['Type'], '#888888')\n",
    "    \n",
    "    # Line width based on absolute position change (thicker = bigger change)\n",
    "    linewidth = 0.5 + abs(pos_change) * 0.02\n",
    "    linewidth = min(linewidth, 3.0)  # Cap at 3\n",
    "    \n",
    "    # Alpha based on position change magnitude\n",
    "    alpha = 0.3 + min(abs(pos_change) / 50, 0.4)  # 0.3 to 0.7\n",
    "    \n",
    "    # Draw curved line (using bezier curve)\n",
    "    x1, y1 = wiki_x + 0.05, wiki_pos\n",
    "    x2, y2 = grok_x - 0.05, grok_pos\n",
    "    \n",
    "    # Create curved path with control points\n",
    "    verts = [(x1, y1), \n",
    "             ((x1 + x2) / 2, y1),  # Control point 1\n",
    "             ((x1 + x2) / 2, y2),  # Control point 2\n",
    "             (x2, y2)]\n",
    "    codes = [Path.MOVETO, Path.CURVE4, Path.CURVE4, Path.CURVE4]\n",
    "    path = Path(verts, codes)\n",
    "    \n",
    "    patch = patches.PathPatch(path, edgecolor=line_color, facecolor='none', \n",
    "                              linewidth=linewidth, alpha=alpha, zorder=1)\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "# Add titles for each side\n",
    "ax.text(wiki_x, -2, 'Wikipedia Top 100', ha='center', fontsize=18)\n",
    "ax.text(grok_x, -2, 'Grokipedia Top 100', ha='center', fontsize=18)\n",
    "\n",
    "# Remove axes decorations\n",
    "ax.axis('off')\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor=colors_map.get(t, '#cccccc'), label=t, edgecolor='black', alpha=0.8)\n",
    "    for t in all_types\n",
    "    if (t in wiki_ranked['Type'].unique()) or (t in grok_ranked['Type'].unique())\n",
    "]\n",
    "fig2.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, 0.03), \n",
    "           ncol=min(len(legend_elements), 6), fontsize=13, frameon=True, title='Domain Type')\n",
    "\n",
    "# Add text explaining the visualization\n",
    "fig2.text(0.5, 0.02, 'Lines connect domains appearing in both lists. Line thickness indicates magnitude of position change.',\n",
    "         ha='center', fontsize=13, style='italic')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.98])\n",
    "plt.savefig(\"../graphics/domain_position_comparison_t100.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(t100_wiki.domain).intersection(set(t100_grok.domain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc997223",
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_wiki.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_grok.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_wiki.groupby('Type').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t100_grok.groupby('Type').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce50f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
